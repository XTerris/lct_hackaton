
# Хакатон Лидеры цифровой трансформации

**Кейс:** Сервис выделения сущностей из поискового запроса клиента в мобильном приложении торговой сети «Пятерочка»

**Краткое описание:** Решение задачи Named Entity Recognition (NER) для выделения сущностей из текстовых запросов на основе модели RuRoBERTa с конвертацией в ONNX формат для оптимизации инференса.
**Презентация:** `presentation.pptx`

## Описание проекта

Проект представляет собой FastAPI-сервис для выделения сущностей из поисковых запросов пользователей. Модель обучена распознавать типы сущностей, перечисленные в таблице:
| Метка    | Значение                                 |
| -------- | ---------------------------------------- |
| TYPE     | Тип товара                               |
| BRAND    | Бренд или производитель                  |
| VOLUME   | Объём, вес и т.д.                        |
| PERCENT  | Процентные значения (например, жирность) |
| O        | Другое                                   |

## Ход работы

### Данные для обучения

Для обучения был использован предоставленный организаторами датасет (`data/train.csv`). А также его дополненная версия, сформированная на основе открытого датасета с Kaggle: [Russian Supermarket Prices (2019-2022)](https://www.kaggle.com/datasets/dadalyndell/russian-groceries-prices-2019-2022). Скрипты для разметки представлены в Jupyter-ноутбуке `mark_newproducts.ipynb`.

### Базовая модель
В качестве базовой модели была выбрана предобученная модель от Сбера: `sberbank-ai/ruRoberta-large`:
- Архитектура: RoBERTa (Robustly Optimized BERT Pretraining Approach)
- Размер: Large (24 слоя, 1024 hidden size, 16 attention heads)
- Специализация: русский язык
- Параметры: ~355M параметров
- Размер словаря: 50265 токенов

Она была выбрана, потому что она основана на архитектуре трансформер, которая показывает хорошие результаты в классификации слов с учётом контекста, а также предобучена на корпусе текстов на русском языке.

### Fine-tuning (дообучение)
Модель была дообучена для задачи Token Classification (классификация токенов, в данном случае адаптация для классификации слов). Обучение выполнялось 5 эпох:
- Первые 3 эпохи на предоставленном датасете (`train.csv`)
- Следующие 2 эпохи на дополненном датасете (`train_extended.csv`)

Процесс обучения описан в файле `train_roberta.py`.

### Подготовка к инференсу

Далее было принято решение конвертировать модель в формат ONNX (Open Neural Network Exchange). Он представляет собой открытый формат для представления моделей машинного обучения, который обеспечивает:
1. **Производительность**: ускорение инференса в 2-3 раза по сравнению с PyTorch и меньшее потребление памяти.
2. **Совместимость**: независимость от фреймворка обучения и кроссплатформенность.
3. **Удобство развёртывания**: уменьшение размера итогового Docker-образа и свободу выбора среды выполнения.

Конвертация выполняется скриптом `convert_to_onnx.py`.

### Создание веб-сервиса

Для доступа к модели был разработан простейший FastAPI сервер, предоставляющий эндпоинт `/api/predict` для получения предсказаний модели в формате JSON. Пример ответа:

```json
[
  {
    "start_index": 0,
    "end_index": 6,
    "entity": "B-TYPE"
  },
  {
    "start_index": 7,
    "end_index": 13,
    "entity": "B-BRAND"
  },
  {
    "start_index": 14,
    "end_index": 18,
    "entity": "B-PERCENT"
  },
  {
    "start_index": 19,
    "end_index": 21,
    "entity": "B-VOLUME"
  }
]
```

### Сборка Docker-образа

Для запуска контейнера был написан `Dockerfile`, который инкапсулирует все зависимости и с помощью веб-сервера `gunicorn` запускает 4 воркера с FastAPI приложением, балансируя запросы между ними.

Сборка и запуск контейнера выполняются командами:

```bash
docker build . -t hackaton
docker run -it hackaton
```

### Развёртывание

Для развёртывания веб-сервиса были использованы инструменты Яндекс Cloud, а конкретно DataSphere Node и API Gateway:
- В DataSphere Node запускается 5 инстансов сервиса (на CPU, на GPU можно уменьшить их количество)
- API Gateway перенаправляет запросы к Node'ам
